{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrTW7nDwqASl"
   },
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR9Wgw8lqASo",
    "outputId": "3fd3e52c-1b27-4f85-d71e-354c0ee8b5c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/martin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/martin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/martin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "# nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # download for lemmatization\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# other models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "u-KUTc1kqASq"
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterData.db')\n",
    "df = pd.read_sql_table('TextMessages', engine)\n",
    "X = df[[\"message\", \"original\", \"genre\"]]\n",
    "Y = df.drop(columns= [\"id\", \"message\", \"original\", \"genre\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DBmXCwbqASr"
   },
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Xfgvt4eLqASr"
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Normalization\n",
    "    \n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation characters - this regex finds everything which is not a combination of letters\n",
    "    # and numbers and replaces it with a whitespace\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    \n",
    "    # Tokenization\n",
    "    \n",
    "    # Split into tokens\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Part-of-speech tagging maybe useful here?\n",
    "    # Named Entity Recognition usefuk here?\n",
    "    \n",
    "    # Stemming - only keep the stem of a word, simple find and replace method which removes f.e. \"ing\"\n",
    "    # stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "    \n",
    "    # Lemmatization - more complex appraoch using dictionaries which can f.e. map \"is\" and \"was\" to \"be\"\n",
    "    # Lemmatize verbs by specifying pos\n",
    "    lemmed_verbs = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
    "    # Reduce nouns to their root form\n",
    "    lemmed_nouns = [WordNetLemmatizer().lemmatize(w) for w in lemmed_verbs]\n",
    "    return lemmed_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5LpueGxsqyc_"
   },
   "outputs": [],
   "source": [
    "# Split the data in training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.05) # We drastically decrease the train_size to allow our GridSearch to run in a feasible amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Yv1xIlnArACF"
   },
   "outputs": [],
   "source": [
    "# Calculate the average accuracy for each target column\n",
    "def print_acc(name, model, y_test, y_pred):\n",
    "    columns = y_test.columns\n",
    "    y_pred_df = pd.DataFrame(y_pred, columns = columns)\n",
    "    accuracy = (y_pred_df == y_test.reset_index().drop([\"index\"], axis = 1)).mean()\n",
    "    report = classification_report(y_true = y_test,\n",
    "                              y_pred = y_pred,\n",
    "                              target_names = list(y_test.columns),\n",
    "                            #  output_dict = True,\n",
    "                              zero_division = 0)\n",
    "    print(f\"F1 score, recall and precision per category {name}: \\n\")\n",
    "    # print(f\"Average accuracy: {accuracy.mean()}\")\n",
    "    # print(accuracy)\n",
    "    print(report)\n",
    "    \n",
    "    return {'name' : name, 'model': model, 'report' : report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "oYa2dVCeOljw"
   },
   "outputs": [],
   "source": [
    "# Create an empty array to store all the results and the models to find the best one in the end\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_6GvgH5qASs"
   },
   "source": [
    "# Native model without optimization (MultiOutputClassifier with RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KLuoHL9xqASs"
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#         ('features', FeatureUnion([\n",
    "\n",
    "#             ('text_pipeline', Pipeline([\n",
    "#                 ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#                 ('tfidf', TfidfTransformer())\n",
    "#             ]))\n",
    "#         ])),\n",
    "\n",
    "#         ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "#     ])\n",
    "\n",
    "random_forest_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "\n",
    "random_forest_pipe.fit(X_train[\"message\"], y_train)\n",
    "y_pred = random_forest_pipe.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea7ozGZ0qASv",
    "outputId": "6582686e-dcb8-4e11-8e39-d81425843385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score, recall and precision per category MultiOutputClassifier RandomForest: \n",
      "\n",
      "{'related': {'precision': 0.8064771627211124, 'recall': 0.9589284779992675, 'f1-score': 0.8761203661655393, 'support': 19113}, 'request': {'precision': 0.7895659798334064, 'recall': 0.42486435480066054, 'f1-score': 0.5524539877300614, 'support': 4239}, 'offer': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 112}, 'aid_related': {'precision': 0.7265138154027043, 'recall': 0.598624297616741, 'f1-score': 0.6563977266691454, 'support': 10322}, 'medical_help': {'precision': 0.75, 'recall': 0.0015113350125944584, 'f1-score': 0.0030165912518853692, 'support': 1985}, 'medical_products': {'precision': 0.8, 'recall': 0.003218020917135961, 'f1-score': 0.00641025641025641, 'support': 1243}, 'search_and_rescue': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 697}, 'security': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 454}, 'military': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 824}, 'water': {'precision': 0.8558558558558559, 'recall': 0.060202788339670466, 'f1-score': 0.11249259917110717, 'support': 1578}, 'food': {'precision': 0.8126635269492413, 'recall': 0.5616636528028933, 'f1-score': 0.6642429426860564, 'support': 2765}, 'shelter': {'precision': 0.8462929475587704, 'recall': 0.21224489795918366, 'f1-score': 0.33937635968092816, 'support': 2205}, 'clothing': {'precision': 0.7619047619047619, 'recall': 0.041666666666666664, 'f1-score': 0.07901234567901234, 'support': 384}, 'money': {'precision': 1.0, 'recall': 0.0017574692442882249, 'f1-score': 0.003508771929824561, 'support': 569}, 'missing_people': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 288}, 'refugees': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 840}, 'death': {'precision': 0.8571428571428571, 'recall': 0.005249343832020997, 'f1-score': 0.010434782608695651, 'support': 1143}, 'other_aid': {'precision': 0.5081967213114754, 'recall': 0.009497549019607842, 'f1-score': 0.01864661654135338, 'support': 3264}, 'infrastructure_related': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1635}, 'transport': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1147}, 'buildings': {'precision': 0.7142857142857143, 'recall': 0.00784313725490196, 'f1-score': 0.015515903801396431, 'support': 1275}, 'electricity': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 519}, 'tools': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 152}, 'hospitals': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 278}, 'shops': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 114}, 'aid_centers': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 301}, 'other_infrastructure': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1098}, 'weather_related': {'precision': 0.8644484144707458, 'recall': 0.5558587018954624, 'f1-score': 0.6766299597972383, 'support': 6964}, 'floods': {'precision': 0.9375, 'recall': 0.1820388349514563, 'f1-score': 0.3048780487804878, 'support': 2060}, 'storm': {'precision': 0.8169934640522876, 'recall': 0.10789814415192059, 'f1-score': 0.19062142584826536, 'support': 2317}, 'fire': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 270}, 'earthquake': {'precision': 0.9005315110098709, 'recall': 0.5077054794520548, 'f1-score': 0.6493293183684643, 'support': 2336}, 'cold': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 512}, 'other_weather': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1320}, 'direct_report': {'precision': 0.7427027027027027, 'recall': 0.2851805728518057, 'f1-score': 0.412117576484703, 'support': 4818}, 'micro avg': {'precision': 0.7979485107624626, 'recall': 0.44921090206087866, 'f1-score': 0.5748217375135415, 'support': 79141}, 'macro avg': {'precision': 0.41403072672004304, 'recall': 0.12931296356480948, 'f1-score': 0.15917730227441204, 'support': 79141}, 'weighted avg': {'precision': 0.6841460796350334, 'recall': 0.44921090206087866, 'f1-score': 0.4807621728093338, 'support': 79141}, 'samples avg': {'precision': 0.6873152418171691, 'recall': 0.4405194125653719, 'f1-score': 0.4861795276591378, 'support': 79141}}\n"
     ]
    }
   ],
   "source": [
    "results.append(print_acc(\"MultiOutputClassifier RandomForest\", random_forest_pipe, y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Skmc5Huqm0"
   },
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0VjADMcCqASx"
   },
   "outputs": [],
   "source": [
    "# knn_pipe = Pipeline([\n",
    "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', KNeighborsClassifier())\n",
    "#     ])\n",
    "# knn_pipe.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_knn = knn_pipe.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbUvK8ZPu66T",
    "outputId": "526d36bb-92b5-484d-855f-d1529c22d394"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"kNN\", knn_pipe, y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5N0Od0AuuLn"
   },
   "source": [
    "# Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cKw9pdNzuuvR"
   },
   "outputs": [],
   "source": [
    "# decision_tree_pipe = Pipeline([\n",
    "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', DecisionTreeClassifier())\n",
    "#     ])\n",
    "# decision_tree_pipe.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_decision_tree = decision_tree_pipe.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8o7h0swu-b8",
    "outputId": "3118dcdf-07d7-4fc0-b3ce-72ca55fde454"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"Decision Tree\", decision_tree_pipe, y_test, y_pred_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyxC-47wIKoO"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Jt18UDVNISCi"
   },
   "outputs": [],
   "source": [
    "# random_forest_only_pipe = Pipeline([\n",
    "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', RandomForestClassifier())\n",
    "#     ])\n",
    "# random_forest_only_pipe.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_random_forest_only = random_forest_only_pipe.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lILTiPA6OSmX",
    "outputId": "916967b6-e8d6-4c52-b98d-281ef1617c08"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"Random Forest\", random_forest_only_pipe, y_test, y_pred_random_forest_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOIIBf0eR8NU",
    "outputId": "2016bfc2-c161-480a-bbcc-9c87a1191d6c"
   },
   "outputs": [],
   "source": [
    "# for result in results:\n",
    "#   print(result[\"name\"])\n",
    "#   print(result[\"accuracy\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9ZbSLokO-ye"
   },
   "source": [
    "# Improve models using GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z9wmeTCSMKb"
   },
   "source": [
    "## MultiOutputClassifier + RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8RwevSxO-WI",
    "outputId": "0f505ef6-2a9d-4d5a-d1d5-84d0485ec9a4"
   },
   "outputs": [],
   "source": [
    "# Check for available parameters to optimize\n",
    "# random_forest_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gEtxLFsfPDif"
   },
   "outputs": [],
   "source": [
    "# parameters_mo_rf = {\n",
    "#     # vect\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "    \n",
    "#     # tfidf\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "#     'tfidf__norm' : ['l1', 'l2'],\n",
    "#   #  'tfidf__use_idf' : [True, False],\n",
    "#    # 'tfidf__smooth_idf': [True, False],\n",
    "#    # 'tfidf__sublinear_tf' : [True, False],\n",
    "\n",
    "#     # clf\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#     'clf__estimator__criterion' : ['gini', 'entropy'],\n",
    "#     'clf__estimator__n_estimators': [50, 100, 150, 200],\n",
    "#     'clf__estimator__max_depth' : [None, 5, 10],\n",
    "# }\n",
    "\n",
    "# cv_parameters_mo_rf = GridSearchCV(random_forest_pipe, param_grid=parameters_mo_rf) \n",
    "# cv_parameters_mo_rf.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_mo_rf_cv = cv_parameters_mo_rf.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIE9fH5iXrX8",
    "outputId": "c65a85c2-7bc3-45dc-d2af-3745988dfa8e"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"MultiOutputClassifier Random Forest CV\", cv_parameters_mo_rf, y_test, y_pred_mo_rf_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC2PzZIgSTda"
   },
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unz31Y-1XuO2",
    "outputId": "04074bfc-aba6-47a5-bf11-0db13229c336"
   },
   "outputs": [],
   "source": [
    "# knn_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMrFqFS0XuJZ",
    "outputId": "eda65e65-896d-403b-aa40-4cbff666d9b0"
   },
   "outputs": [],
   "source": [
    "# parameters_knn = {\n",
    "#     # vect\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "    \n",
    "#     # tfidf\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "#     'tfidf__norm' : ['l1', 'l2'],\n",
    "#   #  'tfidf__use_idf' : [True, False],\n",
    "#   #  'tfidf__smooth_idf': [True, False],\n",
    "#   #  'tfidf__sublinear_tf' : [True, False],\n",
    "\n",
    "#     # clf\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "#     'clf__n_neighbors' : [3, 5, 8],\n",
    "#     'clf__weights' : ['uniform', 'distance'],\n",
    "#     'clf__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "\n",
    "# }\n",
    "\n",
    "# cv_knn = GridSearchCV(knn_pipe, param_grid=parameters_knn) \n",
    "# cv_knn.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_knn_cv = cv_knn.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWNJIWb6Z7Gg",
    "outputId": "faed75e0-a8dc-469a-db55-5be41a934d4f"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"kNN CV\", cv_knn, y_test, y_pred_mo_rf_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true = y_test,\n",
    "                              y_pred = y_pred,\n",
    "                              target_names = list(y_test.columns),\n",
    "                              output_dict = True,\n",
    "                              zero_division = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk4UwgQrSX6E"
   },
   "source": [
    "# Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9uUyuoWJcZz",
    "outputId": "f2de889a-2fe6-4c62-f76f-b83ed3a28d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier RandomForest\n",
      "0.9399697146986956\n",
      "kNN\n",
      "0.9303656032396095\n",
      "Decision Tree\n",
      "0.9243796675499878\n",
      "Random Forest\n",
      "0.9397701070310077\n",
      "MultiOutputClassifier Random Forest CV\n",
      "0.9394546351424211\n",
      "kNN CV\n",
      "0.9394546351424211\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "  print(result[\"name\"])\n",
    "  print(result[\"accuracy\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIg_hFQZSaMJ"
   },
   "source": [
    "As we can see, the models performed all very similar. Only the decision tree model is a bit worse compared to the other ones. Surprisingly, our unoptimized orginal model with a MultiOutpuClassfier and a RandomForestClassifier performed best. Therefore we can assume that the standard model configuration fits good to our problem and the optimization attempt only leads us away from the optimum. 94% is a quite good result so we can stick with that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "pu1IyfRDJcRh"
   },
   "outputs": [],
   "source": [
    "best_model = results[0]['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FX0t5mtRO8-"
   },
   "source": [
    "Now that we found the best model configuration, we retrain the model with 80% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "R87lA-AcQejZ"
   },
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X, Y, train_size = 0.80)\n",
    "best_model.fit(X_train_new[\"message\"], y_train_new)\n",
    "y_pred_final = best_model.predict(X_test_new[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrzCQwmdqASx"
   },
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "gQCqCcQCqASy"
   },
   "outputs": [],
   "source": [
    "model_params = best_model.get_params()\n",
    "model = best_model\n",
    "\n",
    "fileObj = open('model_params.obj', 'wb')\n",
    "pickle.dump(model_params,fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('model.obj', 'wb')\n",
    "pickle.dump(model,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RFRSYRjqASy"
   },
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAlLehW1qASy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ML Pipeline Preparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
