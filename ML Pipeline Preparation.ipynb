{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrTW7nDwqASl"
   },
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mR9Wgw8lqASo",
    "outputId": "3fd3e52c-1b27-4f85-d71e-354c0ee8b5c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/martin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/martin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/martin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "# nltk\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet') # download for lemmatization\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "# other models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "u-KUTc1kqASq"
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///DisasterData.db')\n",
    "df = pd.read_sql_table('TextMessages', engine)\n",
    "X = df[[\"message\", \"original\", \"genre\"]]\n",
    "Y = df.drop(columns= [\"id\", \"message\", \"original\", \"genre\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DBmXCwbqASr"
   },
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Xfgvt4eLqASr"
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    # Normalization\n",
    "    \n",
    "    # Convert to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove punctuation characters - this regex finds everything which is not a combination of letters\n",
    "    # and numbers and replaces it with a whitespace\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    \n",
    "    # Tokenization\n",
    "    \n",
    "    # Split into tokens\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    \n",
    "    # Remove stopwords\n",
    "    words = [w for w in words if w not in stopwords.words(\"english\")]\n",
    "    \n",
    "    # Part-of-speech tagging maybe useful here?\n",
    "    # Named Entity Recognition usefuk here?\n",
    "    \n",
    "    # Stemming - only keep the stem of a word, simple find and replace method which removes f.e. \"ing\"\n",
    "    # stemmed = [PorterStemmer().stem(w) for w in words]\n",
    "    \n",
    "    # Lemmatization - more complex appraoch using dictionaries which can f.e. map \"is\" and \"was\" to \"be\"\n",
    "    # Lemmatize verbs by specifying pos\n",
    "    lemmed_verbs = [WordNetLemmatizer().lemmatize(w, pos='v') for w in words]\n",
    "    # Reduce nouns to their root form\n",
    "    lemmed_nouns = [WordNetLemmatizer().lemmatize(w) for w in lemmed_verbs]\n",
    "    return lemmed_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5LpueGxsqyc_"
   },
   "outputs": [],
   "source": [
    "# Split the data in training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, train_size = 0.05) # We drastically decrease the train_size to allow our GridSearch to run in a feasible amount of time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Yv1xIlnArACF"
   },
   "outputs": [],
   "source": [
    "# Calculate the average accuracy for each target column\n",
    "def print_acc(name, model, y_test, y_pred):\n",
    "    columns = y_test.columns\n",
    "    y_pred_df = pd.DataFrame(y_pred, columns = columns)\n",
    "    accuracy = (y_pred_df == y_test.reset_index().drop([\"index\"], axis = 1)).mean()\n",
    "    report = classification_report(y_true = y_test,\n",
    "                              y_pred = y_pred,\n",
    "                              target_names = list(y_test.columns),\n",
    "                              output_dict = True,\n",
    "                              zero_division = 0)\n",
    "    print(f\"F1 score, recall and precision per category {name}: \")\n",
    "    # print(f\"Average accuracy: {accuracy.mean()}\")\n",
    "    # print(accuracy)\n",
    "    print(report)\n",
    "    return {'name' : name, 'model': model, 'report' : report}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oYa2dVCeOljw"
   },
   "outputs": [],
   "source": [
    "# Create an empty array to store all the results and the models to find the best one in the end\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_6GvgH5qASs"
   },
   "source": [
    "# Native model without optimization (MultiOutputClassifier with RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "KLuoHL9xqASs"
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#         ('features', FeatureUnion([\n",
    "\n",
    "#             ('text_pipeline', Pipeline([\n",
    "#                 ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#                 ('tfidf', TfidfTransformer())\n",
    "#             ]))\n",
    "#         ])),\n",
    "\n",
    "#         ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "#     ])\n",
    "\n",
    "random_forest_pipe = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "    ])\n",
    "\n",
    "random_forest_pipe.fit(X_train[\"message\"], y_train)\n",
    "y_pred = random_forest_pipe.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea7ozGZ0qASv",
    "outputId": "6582686e-dcb8-4e11-8e39-d81425843385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score, recall and precision per category MultiOutputClassifier RandomForest: \n",
      "{'related': {'precision': 0.8028770706190062, 'recall': 0.9643436829153359, 'f1-score': 0.8762339732153477, 'support': 19099}, 'request': {'precision': 0.847457627118644, 'recall': 0.3758515386422363, 'f1-score': 0.5207485760781123, 'support': 4257}, 'offer': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 113}, 'aid_related': {'precision': 0.7426144288068974, 'recall': 0.5666053980845507, 'f1-score': 0.6427787532923618, 'support': 10337}, 'medical_help': {'precision': 0.6363636363636364, 'recall': 0.0035211267605633804, 'f1-score': 0.007003501750875438, 'support': 1988}, 'medical_products': {'precision': 1.0, 'recall': 0.0015923566878980893, 'f1-score': 0.0031796502384737677, 'support': 1256}, 'search_and_rescue': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 685}, 'security': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 447}, 'military': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 824}, 'water': {'precision': 0.9649122807017544, 'recall': 0.06909547738693467, 'f1-score': 0.12895662368112543, 'support': 1592}, 'food': {'precision': 0.8770949720670391, 'recall': 0.33872707659115425, 'f1-score': 0.4887159533073929, 'support': 2781}, 'shelter': {'precision': 0.8994082840236687, 'recall': 0.13730803974706413, 'f1-score': 0.23824451410658304, 'support': 2214}, 'clothing': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 381}, 'money': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 586}, 'missing_people': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 286}, 'refugees': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 846}, 'death': {'precision': 1.0, 'recall': 0.0043782837127845885, 'f1-score': 0.008718395815170008, 'support': 1142}, 'other_aid': {'precision': 0.5483870967741935, 'recall': 0.005165603160133698, 'f1-score': 0.010234798314268514, 'support': 3291}, 'infrastructure_related': {'precision': 0.4, 'recall': 0.0012345679012345679, 'f1-score': 0.0024615384615384616, 'support': 1620}, 'transport': {'precision': 0.75, 'recall': 0.0026086956521739132, 'f1-score': 0.005199306759098787, 'support': 1150}, 'buildings': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1272}, 'electricity': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 504}, 'tools': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 151}, 'hospitals': {'precision': 1.0, 'recall': 0.0037313432835820895, 'f1-score': 0.007434944237918215, 'support': 268}, 'shops': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 117}, 'aid_centers': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 293}, 'other_infrastructure': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1098}, 'weather_related': {'precision': 0.8557768924302789, 'recall': 0.6191093817552962, 'f1-score': 0.718454720294339, 'support': 6939}, 'floods': {'precision': 0.9199372056514914, 'recall': 0.28529698149951316, 'f1-score': 0.43552582683017466, 'support': 2054}, 'storm': {'precision': 0.7783882783882784, 'recall': 0.18162393162393162, 'f1-score': 0.2945252945252945, 'support': 2340}, 'fire': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 271}, 'earthquake': {'precision': 0.8932806324110671, 'recall': 0.6854419410745234, 'f1-score': 0.7756803138024024, 'support': 2308}, 'cold': {'precision': 1.0, 'recall': 0.00196078431372549, 'f1-score': 0.003913894324853229, 'support': 510}, 'other_weather': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1311}, 'direct_report': {'precision': 0.7100183823529411, 'recall': 0.32053941908713696, 'f1-score': 0.4416809605488851, 'support': 4820}, 'micro avg': {'precision': 0.8030364372469636, 'recall': 0.45107452843299517, 'f1-score': 0.577667036105201, 'support': 79151}, 'macro avg': {'precision': 0.44647190822025423, 'recall': 0.1305181608537078, 'f1-score': 0.1602769011309776, 'support': 79151}, 'weighted avg': {'precision': 0.700867223983633, 'recall': 0.45107452843299517, 'f1-score': 0.48328024780843787, 'support': 79151}, 'samples avg': {'precision': 0.6933749947421353, 'recall': 0.44452078418837704, 'f1-score': 0.4911962789025918, 'support': 79151}}\n"
     ]
    }
   ],
   "source": [
    "results.append(print_acc(\"MultiOutputClassifier RandomForest\", random_forest_pipe, y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1Skmc5Huqm0"
   },
   "source": [
    "# kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0VjADMcCqASx"
   },
   "outputs": [],
   "source": [
    "# knn_pipe = Pipeline([\n",
    "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', KNeighborsClassifier())\n",
    "#     ])\n",
    "# knn_pipe.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_knn = knn_pipe.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbUvK8ZPu66T",
    "outputId": "526d36bb-92b5-484d-855f-d1529c22d394"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"kNN\", knn_pipe, y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5N0Od0AuuLn"
   },
   "source": [
    "# Decision tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cKw9pdNzuuvR"
   },
   "outputs": [],
   "source": [
    "# decision_tree_pipe = Pipeline([\n",
    "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', DecisionTreeClassifier())\n",
    "#     ])\n",
    "# decision_tree_pipe.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_decision_tree = decision_tree_pipe.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q8o7h0swu-b8",
    "outputId": "3118dcdf-07d7-4fc0-b3ce-72ca55fde454"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"Decision Tree\", decision_tree_pipe, y_test, y_pred_decision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyxC-47wIKoO"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Jt18UDVNISCi"
   },
   "outputs": [],
   "source": [
    "# random_forest_only_pipe = Pipeline([\n",
    "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "#         ('clf', RandomForestClassifier())\n",
    "#     ])\n",
    "# random_forest_only_pipe.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_random_forest_only = random_forest_only_pipe.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lILTiPA6OSmX",
    "outputId": "916967b6-e8d6-4c52-b98d-281ef1617c08"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"Random Forest\", random_forest_only_pipe, y_test, y_pred_random_forest_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOIIBf0eR8NU",
    "outputId": "2016bfc2-c161-480a-bbcc-9c87a1191d6c"
   },
   "outputs": [],
   "source": [
    "# for result in results:\n",
    "#   print(result[\"name\"])\n",
    "#   print(result[\"accuracy\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9ZbSLokO-ye"
   },
   "source": [
    "# Improve models using GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z9wmeTCSMKb"
   },
   "source": [
    "## MultiOutputClassifier + RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I8RwevSxO-WI",
    "outputId": "0f505ef6-2a9d-4d5a-d1d5-84d0485ec9a4"
   },
   "outputs": [],
   "source": [
    "# Check for available parameters to optimize\n",
    "# random_forest_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "gEtxLFsfPDif"
   },
   "outputs": [],
   "source": [
    "# parameters_mo_rf = {\n",
    "#     # vect\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "    \n",
    "#     # tfidf\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "#     'tfidf__norm' : ['l1', 'l2'],\n",
    "#   #  'tfidf__use_idf' : [True, False],\n",
    "#    # 'tfidf__smooth_idf': [True, False],\n",
    "#    # 'tfidf__sublinear_tf' : [True, False],\n",
    "\n",
    "#     # clf\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "#     'clf__estimator__criterion' : ['gini', 'entropy'],\n",
    "#     'clf__estimator__n_estimators': [50, 100, 150, 200],\n",
    "#     'clf__estimator__max_depth' : [None, 5, 10],\n",
    "# }\n",
    "\n",
    "# cv_parameters_mo_rf = GridSearchCV(random_forest_pipe, param_grid=parameters_mo_rf) \n",
    "# cv_parameters_mo_rf.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_mo_rf_cv = cv_parameters_mo_rf.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lIE9fH5iXrX8",
    "outputId": "c65a85c2-7bc3-45dc-d2af-3745988dfa8e"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"MultiOutputClassifier Random Forest CV\", cv_parameters_mo_rf, y_test, y_pred_mo_rf_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yC2PzZIgSTda"
   },
   "source": [
    "## kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unz31Y-1XuO2",
    "outputId": "04074bfc-aba6-47a5-bf11-0db13229c336"
   },
   "outputs": [],
   "source": [
    "# knn_pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMrFqFS0XuJZ",
    "outputId": "eda65e65-896d-403b-aa40-4cbff666d9b0"
   },
   "outputs": [],
   "source": [
    "# parameters_knn = {\n",
    "#     # vect\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "    \n",
    "#     # tfidf\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "#     'tfidf__norm' : ['l1', 'l2'],\n",
    "#   #  'tfidf__use_idf' : [True, False],\n",
    "#   #  'tfidf__smooth_idf': [True, False],\n",
    "#   #  'tfidf__sublinear_tf' : [True, False],\n",
    "\n",
    "#     # clf\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "#     'clf__n_neighbors' : [3, 5, 8],\n",
    "#     'clf__weights' : ['uniform', 'distance'],\n",
    "#     'clf__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "\n",
    "# }\n",
    "\n",
    "# cv_knn = GridSearchCV(knn_pipe, param_grid=parameters_knn) \n",
    "# cv_knn.fit(X_train[\"message\"], y_train)\n",
    "# y_pred_knn_cv = cv_knn.predict(X_test[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aWNJIWb6Z7Gg",
    "outputId": "faed75e0-a8dc-469a-db55-5be41a934d4f"
   },
   "outputs": [],
   "source": [
    "# results.append(print_acc(\"kNN CV\", cv_knn, y_test, y_pred_mo_rf_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true = y_test,\n",
    "                              y_pred = y_pred,\n",
    "                              target_names = list(y_test.columns),\n",
    "                              output_dict = True,\n",
    "                              zero_division = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jk4UwgQrSX6E"
   },
   "source": [
    "# Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D9uUyuoWJcZz",
    "outputId": "f2de889a-2fe6-4c62-f76f-b83ed3a28d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier RandomForest\n",
      "0.9399697146986956\n",
      "kNN\n",
      "0.9303656032396095\n",
      "Decision Tree\n",
      "0.9243796675499878\n",
      "Random Forest\n",
      "0.9397701070310077\n",
      "MultiOutputClassifier Random Forest CV\n",
      "0.9394546351424211\n",
      "kNN CV\n",
      "0.9394546351424211\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "  print(result[\"name\"])\n",
    "  print(result[\"accuracy\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIg_hFQZSaMJ"
   },
   "source": [
    "As we can see, the models performed all very similar. Only the decision tree model is a bit worse compared to the other ones. Surprisingly, our unoptimized orginal model with a MultiOutpuClassfier and a RandomForestClassifier performed best. Therefore we can assume that the standard model configuration fits good to our problem and the optimization attempt only leads us away from the optimum. 94% is a quite good result so we can stick with that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "pu1IyfRDJcRh"
   },
   "outputs": [],
   "source": [
    "best_model = results[0]['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FX0t5mtRO8-"
   },
   "source": [
    "Now that we found the best model configuration, we retrain the model with 80% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "R87lA-AcQejZ"
   },
   "outputs": [],
   "source": [
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X, Y, train_size = 0.80)\n",
    "best_model.fit(X_train_new[\"message\"], y_train_new)\n",
    "y_pred_final = best_model.predict(X_test_new[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZrzCQwmdqASx"
   },
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "gQCqCcQCqASy"
   },
   "outputs": [],
   "source": [
    "model_params = best_model.get_params()\n",
    "model = best_model\n",
    "\n",
    "fileObj = open('model_params.obj', 'wb')\n",
    "pickle.dump(model_params,fileObj)\n",
    "fileObj.close()\n",
    "\n",
    "fileObj = open('model.obj', 'wb')\n",
    "pickle.dump(model,fileObj)\n",
    "fileObj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2RFRSYRjqASy"
   },
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAlLehW1qASy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ML Pipeline Preparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
